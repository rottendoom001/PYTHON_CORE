{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document Classification Example with Neural Networks\n",
    "\n",
    "In this document, the performance of Deep Learning algorithms (Multilayer Perceptron and Conventional Neural Networks) is tested for a image classification problem. The images to classify belongs to 4 different documents: laboral contracts, Spanish ID cards, invoices and payrolls."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load libraries\n",
    "\n",
    "We first load the necessary libraries to run the current investigation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.models import Sequential, model_from_json\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras import backend as K\n",
    "from keras.utils import np_utils\n",
    "import os\n",
    "import cv2\n",
    "from imutils import paths\n",
    "import numpy as np\n",
    "from keras.constraints import maxnorm\n",
    "from keras.optimizers import SGD\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Helpers functions\n",
    "\n",
    "In this section section, we will define helper functions that will be used in the rest of the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "images_path = '/home/raul/GIT/tfm/Notebooks/deep_learning/images/'\n",
    "models_path = '/home/raul/GIT/tfm/Notebooks/deep_learning/models/'\n",
    "def get_input_shape(starndard_size):\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        input_shape = (3, starndard_size, starndard_size)\n",
    "    else:\n",
    "        input_shape = (starndard_size, starndard_size, 3)\n",
    "\n",
    "    return input_shape\n",
    "\n",
    "def image_to_feature_vector(image, size, flaten=False):\n",
    "    # resize the image to a fixed size, then flatten the image into\n",
    "    # a list of raw pixel intensities\n",
    "    result = None\n",
    "    try:\n",
    "        if not flaten:\n",
    "            result = cv2.resize(image, size)\n",
    "        else:\n",
    "            result = cv2.resize(image, size).flatten()\n",
    "    except:\n",
    "        print(\"Error loading image \", image)\n",
    "\n",
    "    return result\n",
    "\n",
    "def get_lab_images(dataPath, starndard_size, verbose=False, flaten=False):\n",
    "    imagePaths = list(paths.list_images(dataPath))\n",
    "    freq_verbose = int(len(imagePaths)/25)\n",
    "    data = []\n",
    "    ini_labels = []\n",
    "    for (i, imagePath) in enumerate(imagePaths):\n",
    "        try:\n",
    "            # load the image and extract the class label (assuming that our\n",
    "            # path as the format: /path/to/dataset/{class}.{image_num}.jpg\n",
    "            image = cv2.imread(imagePath)\n",
    "            label = imagePath.split(os.path.sep)[-1].split(\"_\")[0]\n",
    "\n",
    "            # construct a feature vector raw pixel intensities, then update\n",
    "            # the data matrix and labels list\n",
    "            features = image_to_feature_vector(image, size=(starndard_size, starndard_size), \n",
    "                                               flaten=flaten)\n",
    "\n",
    "            if features is not None:\n",
    "                data.append(features)\n",
    "                ini_labels.append(label)\n",
    "        except:\n",
    "            print(\"Error loading image \", imagePath)\n",
    "\n",
    "        if verbose:\n",
    "            # show an update every 50 images\n",
    "            if i > 0 and i % freq_verbose == 0:\n",
    "                print(\"[INFO] processed {}/{}\".format(i, len(imagePaths)))\n",
    "\n",
    "    return data, ini_labels\n",
    "\n",
    "def cure_data(data, ini_labels, num_classes):\n",
    "    le = LabelEncoder()\n",
    "    labels = le.fit_transform(ini_labels)\n",
    "    data = np.array(data) / 255.0\n",
    "    labels = np_utils.to_categorical(labels, num_classes)\n",
    "\n",
    "    return data, labels\n",
    "\n",
    "def config_convNd(input_shape, n_classes, epochs, lrate = 0.01):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), input_shape=input_shape, padding='same',\n",
    "                     activation='relu', kernel_constraint=maxnorm(3)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', padding='same',\n",
    "                     kernel_constraint=maxnorm(3)))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512, activation='relu', kernel_constraint=maxnorm(3)))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(n_classes, activation='softmax'))\n",
    "\n",
    "    lrate = lrate\n",
    "    decay = lrate / epochs\n",
    "    sgd = SGD(lr=lrate, momentum=0.9, decay=decay, nesterov=False)\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=sgd, metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def config_conv2d(input_shape, last_dense):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), input_shape=input_shape))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(32, (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(64))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    #     model.add(Dense(1))\n",
    "    model.add(Dense(last_dense))\n",
    "    model.add(Activation('sigmoid'))\n",
    "\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='rmsprop', metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def config_mlp(input_shape, n_classes, epochs, lrate = 0.01):\n",
    "\n",
    "    # define the architecture of the network\n",
    "    model = Sequential()\n",
    "    model.add(Dense(int(input_shape/4), input_dim=input_shape, init=\"uniform\", activation=\"relu\"))\n",
    "    ## 768 = 3072/4, input_dim = 32*32*3\n",
    "\n",
    "    model.add(Dense(int(input_shape/8), init=\"uniform\", activation=\"relu\"))\n",
    "    ## 384 = 768/2\n",
    "\n",
    "    model.add(Dense(n_classes))\n",
    "    ## 2 --> Number of final claseses\n",
    "\n",
    "    model.add(Activation(\"softmax\"))\n",
    "\n",
    "    decay = lrate / epochs\n",
    "    sgd = SGD(lr=lrate, momentum=0.9, decay=decay, nesterov=False)\n",
    "    \n",
    "    ## lr = 0.01, learning rate\n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer=sgd, metrics=[\"accuracy\"])\n",
    "    \n",
    "    return model\n",
    "\n",
    "def save_model(model, model_name, weights_name):\n",
    "    model_json = model.to_json()\n",
    "    with open(model_name, \"w\") as json_file:\n",
    "        json_file.write(model_json)\n",
    "    # serialize weights to HDF5\n",
    "    model.save_weights(weights_name)\n",
    "    print(\"Saved model to disk\")\n",
    "    \n",
    "    \n",
    "def load_model(model_name, weights_name, epochs):\n",
    "\n",
    "    # load json and create model\n",
    "    json_file = open(model_name, 'r')\n",
    "    loaded_model_json = json_file.read()\n",
    "    json_file.close()\n",
    "    loaded_model = model_from_json(loaded_model_json)\n",
    "    # load weights into new model\n",
    "    loaded_model.load_weights(weights_name)\n",
    "    lrate = 0.01\n",
    "    decay = lrate/epochs\n",
    "    sgd = SGD(lr=lrate, momentum=0.9, decay=decay, nesterov=False)\n",
    "    loaded_model.compile(loss='categorical_crossentropy', \n",
    "                  optimizer=sgd, metrics=['accuracy'])\n",
    "\n",
    "    return loaded_model\n",
    "\n",
    "\n",
    "def get_flatten_labels(array):\n",
    "    return np.asarray([np.where(item==1)[0][0] for item in array])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Variables definition\n",
    "\n",
    "Now we define some variables used in the rest of the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape  (32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "STANDARD_SIZE = 32\n",
    "NUM_CLASSES = 4\n",
    "EPOCHS = 75\n",
    "BATCH_SIZE = 128\n",
    "dataPath  = \"/home/raul/data_tfm_rsm/documents/data_train/\"\n",
    "input_shape = get_input_shape(starndard_size = STANDARD_SIZE)\n",
    "print(\"Input shape \", input_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Multilayer Perceptron\n",
    "\n",
    "We first start studing the Multilayer Perceptron model.\n",
    "\n",
    "#### 3.1 Multilayer Perceptron: Data Loading\n",
    "\n",
    "We first load the data in the correct format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] processed 398/9957\n",
      "[INFO] processed 796/9957\n",
      "[INFO] processed 1194/9957\n",
      "[INFO] processed 1592/9957\n",
      "[INFO] processed 1990/9957\n",
      "[INFO] processed 2388/9957\n",
      "[INFO] processed 2786/9957\n",
      "[INFO] processed 3184/9957\n",
      "[INFO] processed 3582/9957\n",
      "[INFO] processed 3980/9957\n",
      "[INFO] processed 4378/9957\n",
      "[INFO] processed 4776/9957\n",
      "[INFO] processed 5174/9957\n",
      "[INFO] processed 5572/9957\n",
      "[INFO] processed 5970/9957\n",
      "[INFO] processed 6368/9957\n",
      "[INFO] processed 6766/9957\n",
      "[INFO] processed 7164/9957\n",
      "[INFO] processed 7562/9957\n",
      "[INFO] processed 7960/9957\n",
      "[INFO] processed 8358/9957\n",
      "[INFO] processed 8756/9957\n",
      "[INFO] processed 9154/9957\n",
      "[INFO] processed 9552/9957\n",
      "[INFO] processed 9950/9957\n"
     ]
    }
   ],
   "source": [
    "ini_data_mlp, ini_labels_mlp = get_lab_images(dataPath, starndard_size = STANDARD_SIZE,\n",
    "                                              verbose=True, flaten=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We check that everything is working fine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9957 9957\n"
     ]
    }
   ],
   "source": [
    "print(len(ini_data_mlp), len(ini_labels_mlp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contrato\n"
     ]
    }
   ],
   "source": [
    "print(ini_labels_mlp[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# data_mlp, labels_mlp = cure_data(ini_data_mlp, ini_labels_mlp, num_classes=NUM_CLASSES)\n",
    "le = LabelEncoder()\n",
    "labels = le.fit_transform(ini_labels_mlp)\n",
    "data_mlp = np.array(ini_data_mlp) / 255.0\n",
    "labels_mlp = np_utils.to_categorical(labels, NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9957 9957\n"
     ]
    }
   ],
   "source": [
    "print(len(data_mlp), len(labels_mlp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.  0.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "print(labels_mlp[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we split the data into train and test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(train_data_mlp, test_data_mlp, train_labels_mlp, test_labels_mlp) = train_test_split(\n",
    "    data_mlp, labels_mlp, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Multilayer Perceptron: Training\n",
    "\n",
    "Now we train and test the Multilayer Perceptron model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raul/anaconda3/envs/deep_learning/lib/python3.6/site-packages/ipykernel_launcher.py:118: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(768, input_dim=3072, activation=\"relu\", kernel_initializer=\"uniform\")`\n",
      "/home/raul/anaconda3/envs/deep_learning/lib/python3.6/site-packages/ipykernel_launcher.py:121: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(384, activation=\"relu\", kernel_initializer=\"uniform\")`\n"
     ]
    }
   ],
   "source": [
    "model_mlp = config_mlp(input_shape = STANDARD_SIZE*STANDARD_SIZE*3, \n",
    "                       n_classes = NUM_CLASSES, \n",
    "                       epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7467 samples, validate on 2490 samples\n",
      "Epoch 1/75\n",
      "7467/7467 [==============================] - 5s - loss: 1.3634 - acc: 0.3657 - val_loss: 1.3140 - val_acc: 0.3594\n",
      "Epoch 2/75\n",
      "7467/7467 [==============================] - 4s - loss: 1.2335 - acc: 0.4085 - val_loss: 1.1588 - val_acc: 0.4940\n",
      "Epoch 3/75\n",
      "7467/7467 [==============================] - 4s - loss: 1.1337 - acc: 0.4910 - val_loss: 1.1215 - val_acc: 0.4209\n",
      "Epoch 4/75\n",
      "7467/7467 [==============================] - 4s - loss: 1.2366 - acc: 0.4170 - val_loss: 1.2811 - val_acc: 0.4181\n",
      "Epoch 5/75\n",
      "7467/7467 [==============================] - 4s - loss: 1.1212 - acc: 0.4725 - val_loss: 1.3905 - val_acc: 0.3490\n",
      "Epoch 6/75\n",
      "7467/7467 [==============================] - 4s - loss: 1.0555 - acc: 0.5157 - val_loss: 1.0188 - val_acc: 0.5522\n",
      "Epoch 7/75\n",
      "7467/7467 [==============================] - 4s - loss: 1.0323 - acc: 0.5315 - val_loss: 1.0324 - val_acc: 0.5434\n",
      "Epoch 8/75\n",
      "7467/7467 [==============================] - 4s - loss: 1.0431 - acc: 0.5202 - val_loss: 1.1802 - val_acc: 0.4554\n",
      "Epoch 9/75\n",
      "7467/7467 [==============================] - 4s - loss: 1.0105 - acc: 0.5511 - val_loss: 1.0024 - val_acc: 0.5430\n",
      "Epoch 10/75\n",
      "7467/7467 [==============================] - 4s - loss: 1.0574 - acc: 0.5219 - val_loss: 1.0231 - val_acc: 0.5261\n",
      "Epoch 11/75\n",
      "7467/7467 [==============================] - 4s - loss: 0.9592 - acc: 0.5748 - val_loss: 0.9698 - val_acc: 0.5755\n",
      "Epoch 12/75\n",
      "7467/7467 [==============================] - 4s - loss: 1.0121 - acc: 0.5512 - val_loss: 0.9588 - val_acc: 0.5867\n",
      "Epoch 13/75\n",
      "7467/7467 [==============================] - 4s - loss: 0.9371 - acc: 0.5922 - val_loss: 0.9239 - val_acc: 0.6124\n",
      "Epoch 14/75\n",
      "7467/7467 [==============================] - 4s - loss: 1.0971 - acc: 0.4995 - val_loss: 1.1239 - val_acc: 0.4598\n",
      "Epoch 15/75\n",
      "7467/7467 [==============================] - 4s - loss: 0.9855 - acc: 0.5544 - val_loss: 0.9998 - val_acc: 0.5434\n",
      "Epoch 16/75\n",
      "7467/7467 [==============================] - 4s - loss: 0.9546 - acc: 0.5724 - val_loss: 1.0250 - val_acc: 0.5466\n",
      "Epoch 17/75\n",
      "7467/7467 [==============================] - 4s - loss: 0.9014 - acc: 0.6144 - val_loss: 0.9474 - val_acc: 0.5900\n",
      "Epoch 18/75\n",
      "7467/7467 [==============================] - 4s - loss: 0.9221 - acc: 0.5814 - val_loss: 0.9653 - val_acc: 0.5863\n",
      "Epoch 19/75\n",
      "7467/7467 [==============================] - 4s - loss: 0.9609 - acc: 0.5543 - val_loss: 0.9914 - val_acc: 0.5582\n",
      "Epoch 20/75\n",
      "7467/7467 [==============================] - 4s - loss: 0.9238 - acc: 0.5903 - val_loss: 0.9243 - val_acc: 0.5964\n",
      "Epoch 21/75\n",
      "7467/7467 [==============================] - 4s - loss: 0.8894 - acc: 0.6115 - val_loss: 0.9388 - val_acc: 0.5936\n",
      "Epoch 22/75\n",
      "7467/7467 [==============================] - 4s - loss: 0.9001 - acc: 0.6134 - val_loss: 0.9102 - val_acc: 0.6161\n",
      "Epoch 23/75\n",
      "7467/7467 [==============================] - 5s - loss: 0.8989 - acc: 0.5942 - val_loss: 0.9906 - val_acc: 0.5570\n",
      "Epoch 24/75\n",
      "7467/7467 [==============================] - 4s - loss: 0.8857 - acc: 0.6008 - val_loss: 1.0217 - val_acc: 0.5482\n",
      "Epoch 25/75\n",
      "7467/7467 [==============================] - 5s - loss: 0.8992 - acc: 0.6005 - val_loss: 0.9862 - val_acc: 0.5570\n",
      "Epoch 26/75\n",
      "7467/7467 [==============================] - 4s - loss: 0.8995 - acc: 0.5994 - val_loss: 0.9641 - val_acc: 0.5598\n",
      "Epoch 27/75\n",
      "7467/7467 [==============================] - 4s - loss: 0.9031 - acc: 0.6025 - val_loss: 1.0447 - val_acc: 0.4839\n",
      "Epoch 28/75\n",
      "7467/7467 [==============================] - 4s - loss: 0.9221 - acc: 0.5926 - val_loss: 0.9883 - val_acc: 0.5506\n",
      "Epoch 29/75\n",
      "7467/7467 [==============================] - 4s - loss: 0.9471 - acc: 0.5815 - val_loss: 0.9304 - val_acc: 0.6016\n",
      "Epoch 30/75\n",
      "7467/7467 [==============================] - 4s - loss: 0.8498 - acc: 0.6337 - val_loss: 0.9122 - val_acc: 0.5984\n",
      "Epoch 31/75\n",
      "7467/7467 [==============================] - 4s - loss: 0.8385 - acc: 0.6332 - val_loss: 0.9018 - val_acc: 0.6104\n",
      "Epoch 32/75\n",
      "7467/7467 [==============================] - 5s - loss: 0.8065 - acc: 0.6513 - val_loss: 0.9231 - val_acc: 0.5747\n",
      "Epoch 33/75\n",
      "7467/7467 [==============================] - 5s - loss: 0.8773 - acc: 0.6093 - val_loss: 0.9048 - val_acc: 0.6257\n",
      "Epoch 34/75\n",
      "7467/7467 [==============================] - 4s - loss: 0.9034 - acc: 0.5996 - val_loss: 1.0285 - val_acc: 0.5566\n",
      "Epoch 35/75\n",
      "7467/7467 [==============================] - 4s - loss: 0.8550 - acc: 0.6276 - val_loss: 1.2745 - val_acc: 0.4586\n",
      "Epoch 36/75\n",
      "7467/7467 [==============================] - 4s - loss: 0.9095 - acc: 0.6041 - val_loss: 0.9434 - val_acc: 0.5936\n",
      "Epoch 37/75\n",
      "7467/7467 [==============================] - 4s - loss: 0.8212 - acc: 0.6531 - val_loss: 0.9301 - val_acc: 0.5851\n",
      "Epoch 38/75\n",
      "7467/7467 [==============================] - 4s - loss: 0.8037 - acc: 0.6509 - val_loss: 1.1584 - val_acc: 0.5249\n",
      "Epoch 39/75\n",
      "7467/7467 [==============================] - 4s - loss: 0.8437 - acc: 0.6262 - val_loss: 1.0524 - val_acc: 0.5414\n",
      "Epoch 40/75\n",
      "7467/7467 [==============================] - 4s - loss: 0.8394 - acc: 0.6400 - val_loss: 0.8747 - val_acc: 0.6301\n",
      "Epoch 41/75\n",
      "7467/7467 [==============================] - 4s - loss: 0.7808 - acc: 0.6637 - val_loss: 0.9521 - val_acc: 0.5964\n",
      "Epoch 42/75\n",
      "7467/7467 [==============================] - 4s - loss: 0.7876 - acc: 0.6608 - val_loss: 1.1585 - val_acc: 0.51650.6\n",
      "Epoch 43/75\n",
      "7467/7467 [==============================] - 4s - loss: 0.8144 - acc: 0.6491 - val_loss: 0.9910 - val_acc: 0.5534\n",
      "Epoch 44/75\n",
      "7467/7467 [==============================] - 4s - loss: 0.7873 - acc: 0.6560 - val_loss: 0.8859 - val_acc: 0.6036\n",
      "Epoch 45/75\n",
      "7467/7467 [==============================] - 4s - loss: 0.7712 - acc: 0.6667 - val_loss: 0.9247 - val_acc: 0.5972\n",
      "Epoch 46/75\n",
      "7467/7467 [==============================] - 4s - loss: 0.7858 - acc: 0.6605 - val_loss: 0.9935 - val_acc: 0.5482\n",
      "Epoch 47/75\n",
      "7467/7467 [==============================] - 4s - loss: 0.7605 - acc: 0.6715 - val_loss: 0.8705 - val_acc: 0.6285\n",
      "Epoch 48/75\n",
      "7467/7467 [==============================] - 4s - loss: 0.7405 - acc: 0.6849 - val_loss: 0.9040 - val_acc: 0.5988\n",
      "Epoch 49/75\n",
      "7467/7467 [==============================] - 4s - loss: 0.7741 - acc: 0.6613 - val_loss: 1.0213 - val_acc: 0.5735\n",
      "Epoch 50/75\n",
      "7467/7467 [==============================] - 4s - loss: 0.7939 - acc: 0.6494 - val_loss: 0.9142 - val_acc: 0.6016\n",
      "Epoch 51/75\n",
      "7467/7467 [==============================] - 4s - loss: 0.7696 - acc: 0.6606 - val_loss: 0.8579 - val_acc: 0.6438\n",
      "Epoch 52/75\n",
      "7467/7467 [==============================] - 4s - loss: 0.8504 - acc: 0.6439 - val_loss: 0.9702 - val_acc: 0.5819\n",
      "Epoch 53/75\n",
      "7467/7467 [==============================] - 4s - loss: 0.7834 - acc: 0.6653 - val_loss: 0.8638 - val_acc: 0.6426\n",
      "Epoch 54/75\n",
      "7467/7467 [==============================] - 5s - loss: 0.7487 - acc: 0.6752 - val_loss: 0.8595 - val_acc: 0.6373\n",
      "Epoch 55/75\n",
      "7467/7467 [==============================] - 5s - loss: 0.7729 - acc: 0.6669 - val_loss: 0.9482 - val_acc: 0.6016\n",
      "Epoch 56/75\n",
      "7467/7467 [==============================] - 5s - loss: 0.7763 - acc: 0.6657 - val_loss: 0.8997 - val_acc: 0.6137\n",
      "Epoch 57/75\n",
      "7467/7467 [==============================] - 5s - loss: 0.8342 - acc: 0.6369 - val_loss: 1.2929 - val_acc: 0.5426\n",
      "Epoch 58/75\n",
      "7467/7467 [==============================] - 5s - loss: 0.9304 - acc: 0.6093 - val_loss: 0.9526 - val_acc: 0.5526\n",
      "Epoch 59/75\n",
      "7467/7467 [==============================] - 5s - loss: 0.7884 - acc: 0.6653 - val_loss: 0.8989 - val_acc: 0.6333\n",
      "Epoch 60/75\n",
      "7467/7467 [==============================] - 5s - loss: 0.7731 - acc: 0.6655 - val_loss: 0.9819 - val_acc: 0.5542\n",
      "Epoch 61/75\n",
      "7467/7467 [==============================] - 5s - loss: 0.7362 - acc: 0.6874 - val_loss: 0.9835 - val_acc: 0.5819\n",
      "Epoch 62/75\n",
      "7467/7467 [==============================] - 5s - loss: 0.7608 - acc: 0.6738 - val_loss: 0.8829 - val_acc: 0.6229\n",
      "Epoch 63/75\n",
      "7467/7467 [==============================] - 5s - loss: 0.7395 - acc: 0.6811 - val_loss: 0.8966 - val_acc: 0.6141\n",
      "Epoch 64/75\n",
      "7467/7467 [==============================] - 5s - loss: 0.7195 - acc: 0.6913 - val_loss: 0.9079 - val_acc: 0.6145\n",
      "Epoch 65/75\n",
      "7467/7467 [==============================] - 5s - loss: 0.7343 - acc: 0.6842 - val_loss: 1.0724 - val_acc: 0.5920\n",
      "Epoch 66/75\n",
      "7467/7467 [==============================] - 5s - loss: 0.7496 - acc: 0.6813 - val_loss: 0.8634 - val_acc: 0.6345\n",
      "Epoch 67/75\n",
      "7467/7467 [==============================] - 5s - loss: 0.7282 - acc: 0.6892 - val_loss: 0.8677 - val_acc: 0.6406\n",
      "Epoch 68/75\n",
      "7467/7467 [==============================] - 5s - loss: 0.6952 - acc: 0.7016 - val_loss: 0.9161 - val_acc: 0.6305\n",
      "Epoch 69/75\n",
      "7467/7467 [==============================] - 4s - loss: 0.7026 - acc: 0.7005 - val_loss: 0.9534 - val_acc: 0.6060\n",
      "Epoch 70/75\n",
      "7467/7467 [==============================] - 5s - loss: 0.7274 - acc: 0.6909 - val_loss: 0.8998 - val_acc: 0.6197\n",
      "Epoch 71/75\n",
      "7467/7467 [==============================] - 5s - loss: 0.6927 - acc: 0.7067 - val_loss: 0.8615 - val_acc: 0.6430\n",
      "Epoch 72/75\n",
      "7467/7467 [==============================] - 5s - loss: 0.6900 - acc: 0.7085 - val_loss: 1.0462 - val_acc: 0.5751\n",
      "Epoch 73/75\n",
      "7467/7467 [==============================] - 5s - loss: 0.7249 - acc: 0.6977 - val_loss: 1.2460 - val_acc: 0.5341\n",
      "Epoch 74/75\n",
      "7467/7467 [==============================] - 5s - loss: 0.8627 - acc: 0.6343 - val_loss: 0.8725 - val_acc: 0.6289\n",
      "Epoch 75/75\n",
      "7467/7467 [==============================] - 5s - loss: 0.7337 - acc: 0.6948 - val_loss: 0.9625 - val_acc: 0.5936\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3a3a7b8c88>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_mlp.fit(train_data_mlp, train_labels_mlp, validation_data=(test_data_mlp, test_labels_mlp), \n",
    "              epochs=EPOCHS, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "model_name_mlp = models_path + \"model_mlp.json\"\n",
    "weights_name_mlp = models_path +\"model_mlp.h5\"\n",
    "\n",
    "save_model(model_mlp, model_name_mlp, weights_name_mlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3 Multilayer Perceptron: Testing\n",
    "\n",
    "Now we test the model trained in the previous section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Evaluating MLP model...\n",
      "2432/2490 [============================>.] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] Evaluating MLP model...\")\n",
    "\n",
    "(loss_mlp, accu_mlp) = model_mlp.evaluate(test_data_mlp, test_labels_mlp, \n",
    "                                          batch_size=BATCH_SIZE, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loss_mlp=0.9625, accuracy_mlp: 59.3574%\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] loss_mlp={:.4f}, accuracy_mlp: {:.4f}%\".format(loss_mlp, \n",
    "                                                             accu_mlp * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2464/2490 [============================>.] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "predictions_mlp = model_mlp.predict_classes(test_data_mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "flatten_labels_mlp = get_flatten_labels(test_labels_mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>266</td>\n",
       "      <td>94</td>\n",
       "      <td>127</td>\n",
       "      <td>134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>574</td>\n",
       "      <td>21</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>141</td>\n",
       "      <td>288</td>\n",
       "      <td>151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>49</td>\n",
       "      <td>44</td>\n",
       "      <td>179</td>\n",
       "      <td>350</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted    0    1    2    3\n",
       "Actual                       \n",
       "0          266   94  127  134\n",
       "1            9  574   21    3\n",
       "2           60  141  288  151\n",
       "3           49   44  179  350"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crosstab_df_mlp = pd.crosstab(flatten_labels_mlp, predictions_mlp, rownames=[\"Actual\"], colnames=[\"Predicted\"])\n",
    "pd.crosstab(flatten_labels_mlp, predictions_mlp, rownames=[\"Actual\"], colnames=[\"Predicted\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels_dict = {\"contrato\":0, \"dni\":1, \"factura\":2, \"nomina\":3}\n",
    "actual_val_mlp = np.asarray(crosstab_df_mlp.sum(axis=1))\n",
    "predictions_mlp = np.diag(crosstab_df_mlp)\n",
    "partial_pred_mlp = predictions_mlp/actual_val_mlp\n",
    "total_pred_mlp = sum(predictions_mlp)/sum(actual_val_mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          documento\n",
      "contrato   0.428341\n",
      "dni        0.945634\n",
      "factura    0.450000\n",
      "nomina     0.562701\n",
      "total      0.593574\n"
     ]
    }
   ],
   "source": [
    "accu_dict_mlp = {\"documento\":[partial_pred_mlp[0], partial_pred_mlp[1],\n",
    "                         partial_pred_mlp[2], partial_pred_mlp[3],\n",
    "                         total_pred_mlp]}\n",
    "\n",
    "accu_df_mlp = pd.DataFrame(data = accu_dict_mlp, index = [\"contrato\", \"dni\", \"factura\", \n",
    "                                                    \"nomina\", \"total\"],\n",
    "                           columns = [\"documento\"])\n",
    "\n",
    "print(accu_df_mlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we plot the glocal accuracy and the accuracy per image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAETCAYAAAA/NdFSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f3a3a706d68>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mlp_results = accu_df_mlp.plot(kind=\"bar\", rot=0, legend=False)\n",
    "mlp_results.set_xlabel(\"Documento\")\n",
    "mlp_results.set_ylabel(\"Precisión\")\n",
    "mlp_results.set_title(\"Precisión por cada Documento: MLP\")\n",
    "plt.savefig(images_path+'analysis_mlp.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, while the accuracy regarding the DNI is very high, the accuracy for the rest of documents ranges between 0.4 and 0.6, with a global accuracy of 0.6."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Convolutional Neural Network\n",
    "\n",
    "Now, we will repeat the process but in this case for the Convolutional Neural Network.\n",
    "\n",
    "#### 4.1 Convolutional Neural Network: Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] processed 398/9957\n",
      "[INFO] processed 796/9957\n",
      "[INFO] processed 1194/9957\n",
      "[INFO] processed 1592/9957\n",
      "[INFO] processed 1990/9957\n",
      "[INFO] processed 2388/9957\n",
      "[INFO] processed 2786/9957\n",
      "[INFO] processed 3184/9957\n",
      "[INFO] processed 3582/9957\n",
      "[INFO] processed 3980/9957\n",
      "[INFO] processed 4378/9957\n",
      "[INFO] processed 4776/9957\n",
      "[INFO] processed 5174/9957\n",
      "[INFO] processed 5572/9957\n",
      "[INFO] processed 5970/9957\n",
      "[INFO] processed 6368/9957\n",
      "[INFO] processed 6766/9957\n",
      "[INFO] processed 7164/9957\n",
      "[INFO] processed 7562/9957\n",
      "[INFO] processed 7960/9957\n",
      "[INFO] processed 8358/9957\n",
      "[INFO] processed 8756/9957\n",
      "[INFO] processed 9154/9957\n",
      "[INFO] processed 9552/9957\n",
      "[INFO] processed 9950/9957\n"
     ]
    }
   ],
   "source": [
    "ini_data_cnn, ini_labels_cnn = get_lab_images(dataPath, starndard_size = STANDARD_SIZE,\n",
    "                                              verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9957 9957\n"
     ]
    }
   ],
   "source": [
    "print(len(ini_data_cnn), len(ini_labels_cnn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contrato\n"
     ]
    }
   ],
   "source": [
    "print(ini_labels_cnn[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_cnn, labels_cnn = cure_data(ini_data_cnn, ini_labels_cnn, num_classes=NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9957 9957\n"
     ]
    }
   ],
   "source": [
    "print(len(data_cnn), len(labels_cnn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.  0.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "print(labels_cnn[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(train_data_cnn, test_data_cnn, train_labels_cnn, test_labels_cnn) = train_test_split(\n",
    "    data_cnn, labels_cnn, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 Convolutional Neural Network: Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_cnn = config_convNd(input_shape = input_shape, \n",
    "                         n_classes = NUM_CLASSES, \n",
    "                         epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7467 samples, validate on 2490 samples\n",
      "Epoch 1/35\n",
      "7467/7467 [==============================] - 45s - loss: 1.3709 - acc: 0.3151 - val_loss: 1.3410 - val_acc: 0.2932\n",
      "Epoch 2/35\n",
      "7467/7467 [==============================] - 49s - loss: 1.3323 - acc: 0.3439 - val_loss: 1.3370 - val_acc: 0.2438\n",
      "Epoch 3/35\n",
      "7467/7467 [==============================] - 59s - loss: 1.2343 - acc: 0.4157 - val_loss: 1.1454 - val_acc: 0.4928\n",
      "Epoch 4/35\n",
      "7467/7467 [==============================] - 54s - loss: 1.0359 - acc: 0.5137 - val_loss: 0.9834 - val_acc: 0.5598\n",
      "Epoch 5/35\n",
      "7467/7467 [==============================] - 43s - loss: 0.9661 - acc: 0.5637 - val_loss: 0.9612 - val_acc: 0.6020\n",
      "Epoch 6/35\n",
      "7467/7467 [==============================] - 46s - loss: 0.9089 - acc: 0.6131 - val_loss: 0.8781 - val_acc: 0.6265\n",
      "Epoch 7/35\n",
      "7467/7467 [==============================] - 44s - loss: 0.8629 - acc: 0.6361 - val_loss: 0.8654 - val_acc: 0.6514\n",
      "Epoch 8/35\n",
      "7467/7467 [==============================] - 46s - loss: 0.8389 - acc: 0.6538 - val_loss: 0.8547 - val_acc: 0.6807\n",
      "Epoch 9/35\n",
      "7467/7467 [==============================] - 53s - loss: 0.8111 - acc: 0.6663 - val_loss: 0.8017 - val_acc: 0.6819\n",
      "Epoch 10/35\n",
      "7467/7467 [==============================] - 46s - loss: 0.7821 - acc: 0.6831 - val_loss: 0.7958 - val_acc: 0.6859\n",
      "Epoch 11/35\n",
      "7467/7467 [==============================] - 45s - loss: 0.7618 - acc: 0.6892 - val_loss: 0.7841 - val_acc: 0.6819\n",
      "Epoch 12/35\n",
      "7467/7467 [==============================] - 44s - loss: 0.7762 - acc: 0.6822 - val_loss: 0.7423 - val_acc: 0.7016\n",
      "Epoch 13/35\n",
      "7467/7467 [==============================] - 45s - loss: 0.7343 - acc: 0.6989 - val_loss: 0.7526 - val_acc: 0.7133\n",
      "Epoch 14/35\n",
      "7467/7467 [==============================] - 47s - loss: 0.7049 - acc: 0.7078 - val_loss: 0.7609 - val_acc: 0.6896\n",
      "Epoch 15/35\n",
      "7467/7467 [==============================] - 46s - loss: 0.6734 - acc: 0.7318 - val_loss: 0.7091 - val_acc: 0.7209\n",
      "Epoch 16/35\n",
      "7467/7467 [==============================] - 45s - loss: 0.6534 - acc: 0.7376 - val_loss: 0.7539 - val_acc: 0.6980\n",
      "Epoch 17/35\n",
      "7467/7467 [==============================] - 44s - loss: 0.6377 - acc: 0.7411 - val_loss: 0.7029 - val_acc: 0.7108\n",
      "Epoch 18/35\n",
      "7467/7467 [==============================] - 44s - loss: 0.6168 - acc: 0.7489 - val_loss: 0.6643 - val_acc: 0.7442\n",
      "Epoch 19/35\n",
      "7467/7467 [==============================] - 43s - loss: 0.5840 - acc: 0.7676 - val_loss: 0.6336 - val_acc: 0.7446\n",
      "Epoch 20/35\n",
      "7467/7467 [==============================] - 46s - loss: 0.5593 - acc: 0.7751 - val_loss: 0.6217 - val_acc: 0.7502\n",
      "Epoch 21/35\n",
      "7467/7467 [==============================] - 46s - loss: 0.5348 - acc: 0.7841 - val_loss: 0.6222 - val_acc: 0.7474\n",
      "Epoch 22/35\n",
      "7467/7467 [==============================] - 50s - loss: 0.5157 - acc: 0.7962 - val_loss: 0.5915 - val_acc: 0.7594\n",
      "Epoch 23/35\n",
      "7467/7467 [==============================] - 46s - loss: 0.4885 - acc: 0.8054 - val_loss: 0.5916 - val_acc: 0.7659\n",
      "Epoch 24/35\n",
      "7467/7467 [==============================] - 46s - loss: 0.4621 - acc: 0.8147 - val_loss: 0.5552 - val_acc: 0.7747\n",
      "Epoch 25/35\n",
      "7467/7467 [==============================] - 46s - loss: 0.4334 - acc: 0.8303 - val_loss: 0.5946 - val_acc: 0.7606\n",
      "Epoch 26/35\n",
      "7467/7467 [==============================] - 43s - loss: 0.4034 - acc: 0.8449 - val_loss: 0.5638 - val_acc: 0.7831\n",
      "Epoch 27/35\n",
      "7467/7467 [==============================] - 44s - loss: 0.3987 - acc: 0.8445 - val_loss: 0.5601 - val_acc: 0.7815\n",
      "Epoch 28/35\n",
      "7467/7467 [==============================] - 45s - loss: 0.3727 - acc: 0.8610 - val_loss: 0.5665 - val_acc: 0.7763\n",
      "Epoch 29/35\n",
      "7467/7467 [==============================] - 52s - loss: 0.3463 - acc: 0.8729 - val_loss: 0.5491 - val_acc: 0.7847\n",
      "Epoch 30/35\n",
      "7467/7467 [==============================] - 46s - loss: 0.3165 - acc: 0.8840 - val_loss: 0.5475 - val_acc: 0.7871\n",
      "Epoch 31/35\n",
      "7467/7467 [==============================] - 43s - loss: 0.2921 - acc: 0.8927 - val_loss: 0.5428 - val_acc: 0.7928\n",
      "Epoch 32/35\n",
      "7467/7467 [==============================] - 45s - loss: 0.2729 - acc: 0.8977 - val_loss: 0.5484 - val_acc: 0.7940\n",
      "Epoch 33/35\n",
      "7467/7467 [==============================] - 48s - loss: 0.2640 - acc: 0.9046 - val_loss: 0.5946 - val_acc: 0.7847\n",
      "Epoch 34/35\n",
      "7467/7467 [==============================] - 44s - loss: 0.2509 - acc: 0.9087 - val_loss: 0.5834 - val_acc: 0.7815\n",
      "Epoch 35/35\n",
      "7467/7467 [==============================] - 49s - loss: 0.2214 - acc: 0.9202 - val_loss: 0.5749 - val_acc: 0.7871\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f39f7862c18>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EPOCHS = 35\n",
    "model_cnn.fit(train_data_cnn, train_labels_cnn, validation_data=(test_data_cnn, test_labels_cnn), \n",
    "              epochs=EPOCHS, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "model_name_cnn = models_path + \"model_cnn.json\"\n",
    "weights_name_cnn = models_path + \"model_cnn.h5\"\n",
    "\n",
    "save_model(model_cnn, model_name_cnn, weights_name_cnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3 Convolutional Neural Network: Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Evaluating CNN model...\n",
      "2490/2490 [==============================] - 3s     \n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] Evaluating CNN model...\")\n",
    "\n",
    "(loss_cnn, accu_cnn) = model_cnn.evaluate(test_data_cnn, test_labels_cnn, \n",
    "                                          batch_size=BATCH_SIZE, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loss_cnn=0.5749, accuracy_cnn: 78.7149%\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] loss_cnn={:.4f}, accuracy_cnn: {:.4f}%\".format(loss_cnn, \n",
    "                                                             accu_cnn * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2464/2490 [============================>.] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "predictions_cnn = model_cnn.predict_classes(test_data_cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "flatten_labels = get_flatten_labels(test_labels_cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>512</td>\n",
       "      <td>7</td>\n",
       "      <td>36</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>595</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>77</td>\n",
       "      <td>61</td>\n",
       "      <td>404</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>97</td>\n",
       "      <td>8</td>\n",
       "      <td>68</td>\n",
       "      <td>449</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted    0    1    2    3\n",
       "Actual                       \n",
       "0          512    7   36   66\n",
       "1            0  595   12    0\n",
       "2           77   61  404   98\n",
       "3           97    8   68  449"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crosstab_df_cnn = pd.crosstab(flatten_labels, predictions_cnn, rownames=[\"Actual\"], colnames=[\"Predicted\"])\n",
    "pd.crosstab(flatten_labels, predictions_cnn, rownames=[\"Actual\"], colnames=[\"Predicted\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels_dict = {\"contrato\":0, \"dni\":1, \"factura\":2, \"nomina\":3}\n",
    "actual_val_cnn = np.asarray(crosstab_df_cnn.sum(axis=1))\n",
    "predictions_cnn = np.diag(crosstab_df_cnn)\n",
    "partial_pred_cnn = predictions_cnn/actual_val_cnn\n",
    "total_pred_cnn = sum(predictions_cnn)/sum(actual_val_cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          documento\n",
      "contrato   0.824477\n",
      "dni        0.980231\n",
      "factura    0.631250\n",
      "nomina     0.721865\n",
      "total      0.787149\n"
     ]
    }
   ],
   "source": [
    "accu_dict_cnn = {\"documento\":[partial_pred_cnn[0], partial_pred_cnn[1],\n",
    "                         partial_pred_cnn[2], partial_pred_cnn[3],\n",
    "                         total_pred_cnn]}\n",
    "\n",
    "accu_df_cnn = pd.DataFrame(data = accu_dict_cnn, index = [\"contrato\", \"dni\", \"factura\", \n",
    "                                                    \"nomina\", \"total\"],\n",
    "                           columns = [\"documento\"])\n",
    "\n",
    "print(accu_df_cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAETCAYAAAA/NdFSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAHERJREFUeJzt3Xm4HFW97vHv3tlggARMJB4N54gi8oOHIQhhngRBFIPE\nARRQIYDI5XCuil7JRRRRuYejgKCIEA8BREUFAS+zCA4MBkRlMuTV6NHjlSlISCIJQ5J9/1ir7Uqz\nhw571x6y3s/z5Mnuqq6q1au66621qmt1R3d3N2ZmVp7O4S6AmZkNDweAmVmhHABmZoVyAJiZFcoB\nYGZWKAeAmVmhuoa7APbSRcRrgT8AD1YmdwDnSpo9SNv4HDBf0jf7eM59wJskPZ0fdwDzgDMlfWMw\nyjGcIuI84ElJn12NZX4KbAwsypPWBn4GfFLSksEuY50i4nWkffnuAa5nC+ALwBuAbuBp4FOS7sjz\nu4HTJZ1SWeY9wAmS3hQRRwJfB3aQ9FDlOdcBV0q6ZCDlK5FbAKPfMknbNv4BBwBnRcQ2g7FySZ/p\n6+Cfn7Nt4+CfbQ/MWRMO/gP0vyr7ZUqe9p3hLNBLtDEQA1lBRARwKzBL0jaSpgCfA66LiC0rTz0x\nIvbsY1UdwOURMXYg5bHELYA1jKS/RsTvgc0iYjvgaGA9YJGkvSPiaOB4Uvj/jXR2NS8ixgFfBXYD\nlgPXAJ8CLgYeknRmRJwGvBN4Pi97pKRH85nbJElPRsSngUOB5RFxZV7/Y/mM+Bd5/a8BbgeOkLSy\nWv78vLnAVGBD4DJJp+Z504FTgTHAYuBESfdExGeBXYBXAw9Ien/LOqeRzjw7gWeA4yTdHxEnA9OB\nsbmOPiHp6ohYH/hP0kH70Vwfd1TWdTLpjP6VwKWSPt3GfnkhIk4EHouIzXOdHwv8T2AF8Hiuq9+1\nsy9yWS6p7Js/kcLl7cArcj3tRgrjF4B3SHokIjYCzsv7YC3gu5L+T25N3grcAOwETMzbvDLXxUYR\ncbOk/fvYD5Pz8gdIeqSlCmYCF0u6uVInt0bEocCyyvM+BXwrIqZIWthDVd6a6/5M4IT+6t365hbA\nGiYidgE2Be7Ok7Ykdc/sHRF7AUcAe0h6I/BF4Kr8vM+RDoRbANuSDh57Vdb7L8BHSc3vqcCPSAeK\n6rZnAG/Lz9kGeAi4pPKU1wNvArYG9qmuv8XGefvbAe+NiGkRsTlwAfDuvO7PAD/MB+vGMtv1cPD/\nJ+BbpLDaBvgScEZEbAzsC+yVp38q1wHAaaSD0ubAweSz39y19XFScE0Fdgb+d0Rs2MvrWIWkZcDv\ngK0jYh/gk8De+Wz4O8A1eRt97os+jM3r+jgwi9QVOAX4C3Bkfs5lwGxJ2wM7AvtGxCF53ibAzZJ2\nBE4CvihpBXAM8Id88O91P0h6JLd4Wg/+kAL9zh7q5EZJf6xMuox0cjCrl9fYDXwQOCSHsQ2AWwCj\n3zq5Dx7S/nwSOFzSX1KrmwckLc7z304Kh7vyPICJETGRdDA8MX/gV5APOLnfFeCvwP3AryPiRuBG\nSbe2lOVtpLO8Z/Ljc4FPRcTa+fG1+Yx/SUTMJ51l9uRCSS8AT0fEFcD+pDPWWxsHC0m3RcQTpDNc\nSF1Oy3tY126ks+T78nJXkUMvIo4ADo+ITUkH83F5mX2Bj0rqBhZExNV52e6IOBCYFhGHkQ7QHaTW\nw5O9vJZW3cBS4K3A9yQtyOu+JCLOBV5L//uiNz/I//8BeEzS/ZXHEyNivbyuiRHx+TxvHClk7iG1\nFG7I039Nz/tnH3rfDz/po2wraf+E838A90XEMaTrBKvIrc6jgdmD1dVZKgfA6Lcs9zH35u+Vv8eQ\nulROAoiITmAysJDU1fCPgaHyGf/SxmNJK3MLYirpAPXliPiJpI9U1t/6Ae8kvcc6GmWtzOuuTG9V\nPZB3kg6CPR08OkndGK2vs3Vd1dfVQWqBdAE/BL5Mas38jHSBsaeyLc/Lrgf8BriadJY6m9SF1Nvr\nWEVErEsKjYeAvXt4Skd+Pb3ti9Zyrc2qnqv8/UIP6x+Tl99V0tK87g2BZ0ndbc9XuuR62z/97Yfe\nzCGF7HXViRHxGVLr4tuNaZIWR8ThwI2kVuqLSLo2nxx8k55fq7XBXUBl+RFwaES8Oj8+jtSnCvBj\n4IiI6IyIl5H6fqtdQFNIB66HJf076cA5hVXdDMzIB0pI/ds/l/Qcq+f9uRwTgEOAa4HbgLdExCa5\nPPsA/0Kzq6s3dwNbVC40HkTqEtoTuFfS2aSD/3TSARLgJuDoShkOytPfAKwPnCLpWlL9vKyyXK8i\nYh3gHFLL6c+kunpvREzK82eQrqvMp/d9sYAUwI0D9x79bbcqtwTnACfmdbyc1C1zUF/LkQKpcYB/\nqfvhS8CHIuItjQkR8VbgI6SWZWtZfwGcRepi6s3HSScwb+5n29YLB0BB8gW4/wBuiYgHgMOAd+Wu\njtNIF3fvJ53l3pC7SxrL3g98H7g3Iu4FjgI+1rKJi0gHr3si4mFSH/7hL6Go65C6JOYA50u6VdJc\n0sXrqyLiIeAM4EBJi/pYD5Iez2W4NHeVnQi8D7gc2DAi5gK/IrUgJkbEeOCzpLPKeaTwaXzN9gHS\nGey8iPg18A7SBetNe9n8lyLivvzcu/M2jsjluoUUordFxG/z9Gn5DLy3ffFV4NURIeDbwE/7q8ge\nHAbsHBEP5jJdXj377sVvgRURcQ/wML3sh4iYnF/v5NYVSJoPTAM+EREP5Nd8Ul72odbnZ6fTR7BI\nepb0hQMPafwSdXg4aBtJ8reAzpN05XCXxWxN5xaAmVmh3AIwMyuUWwBmZoVyAJiZFWrU3AewYMGS\nEdFXNWHCuixcuLT/JxbAddHkumhyXTSNhLqYNGl8r/epuAWwmrq6+v3KdzFcF02uiybXRdNIrwsH\ngJlZoRwAZmaFqjUAImKnfGNP6/QDI+KXEfGLiPhQnWUwM7Oe1RYAEfFJ0jjiY1umr0W6Bf4tpPFN\njs1D9pqZ2RCqswXwB+BdPUzfgvQTgwslPU/6oY2+fgHIzMxqUNvXQCX9IP/KUKv1af5OKsASYIP+\n1jdhwroj5or6pEnjh7sII4brosl10eS6aBrJdTEc9wEsBqo1Mp4efvSh1XB/l7Zh0qTxLFgwqn7T\nuzauiybXRZPromkk1EVfATQcAfAw8Ib8K1R/J3X/nDkM5TAzK9qQBUD+Cb1xkmblH8e+mXQNYrak\nvw5VOczMLBk1o4GOlKEgRkKTbjAcdcZtw10EZs/cZ7iLMGjWlPfFYHBdNI2EuvBQEGZm9iIOADOz\nQjkAzMwK5QAwMyuUA8DMrFAOADOzQjkAzMwK5QAwMyuUA8DMrFAOADOzQjkAzMwK5QAwMyuUA8DM\nrFAOADOzQjkAzMwK5QAwMyuUA8DMrFAOADOzQjkAzMwK5QAwMyuUA8DMrFAOADOzQjkAzMwK5QAw\nMyuUA8DMrFAOADOzQjkAzMwK5QAwMyuUA8DMrFAOADOzQjkAzMwK5QAwMytU13AXYCgddcZtw10E\nZs/cZ7iLYGYGuAVgZlas2loAEdEJnA9MAZ4DjpE0vzL/cODjwApgtqSv11UWMzN7sTpbANOBsZJ2\nAWYCZ7XMPxPYF9gN+HhETKixLGZm1qLOANgduAlA0hxgasv8B4ANgLFAB9BdY1nMzKxFnReB1wcW\nVR6viIguScvz44eAXwHPAFdJerqvlU2YsC5dXWPqKekQmjRp/HAXYcRY0+piTXs9A+G6aBrJdVFn\nACwGqq+8s3Hwj4htgLcDrwP+DnwrIg6WdEVvK1u4cGmNRR06CxYsGe4ijBhrUl1MmjR+jXo9A+G6\naBoJddFXANXZBXQncABAROwMPFiZtwhYBiyTtAJ4AvA1ADOzIVRnC+BqYL+IuIvUxz8jIg4Dxkma\nFREXAndExPPAH4BLaiyLmdlqKeG+odoCQNJK4LiWyfMq8y8ALqhr+2Zm1jffCGZmVigHgJlZoRwA\nZmaFcgCYmRXKAWBmVigHgJlZoRwAZmaFcgCYmRXKAWBmVigHgJlZoRwAZmaFKupH4c2sbyUMgGZN\nbgGYmRXKAWBmVigHgJlZoRwAZmaFcgCYmRXKAWBmVigHgJlZoRwAZmaFcgCYmRXKAWBmVigHgJlZ\noRwAZmaFcgCYmRXKAWBmVigHgJlZoRwAZmaFcgCYmRXKAWBmVij/JKQVzz+DaKVyC8DMrFAOADOz\nQjkAzMwKVds1gIjoBM4HpgDPAcdIml+ZvwNwNtABPAa8X9KzdZXHzMxWVWcLYDowVtIuwEzgrMaM\niOgAvgHMkLQ7cBOwcY1lMTOzFm21ACJiY+AEYCLpjB0ASUf1sVjjwI6kORExtTJvM+BvwMciYivg\neklazbKbmdkAtNsF9H3g9vyvu81l1gcWVR6viIguScuBDYFdSaEyH7guIu6V1Ov38SZMWJeurjFt\nbnrkmjRp/HAXYcRwXTS5LppcF01110W7AbCWpE+s5roXA9XSd+aDP6Sz//mSHgaIiJuAqUCvAbBw\n4dLV3PzItGDBkuEuwojhumhyXTS5LpoGoy76CpF2rwHcEREHRsTaq7HdO4EDACJiZ+DByrw/AuMi\nYtP8eA/gt6uxbjMzG6B2WwDvIXXXEBGNad2S+uqTuRrYLyLuIl03mBERhwHjJM2KiKOB7+QLwndJ\nuv4lvQIzM3tJ2goASZNXd8WSVgLHtUyeV5l/G7Dj6q7XzMwGR7vfAloXOBV4c17mNuDTkp6psWxm\nZlajPq8BRMRB+c+vAesBRwFHAGsDF9RbNDMzq1N/LYDTI+LtwHaSplSmnxARc2ssl5mZ1azPFoCk\nrYBzgM6IeHljev57ea8LmpnZiNfvNQBJcyPibOCXEfF/Sd/oORD497oLZ2Zm9WnrPgBJFwPvJH1/\n/7+Ad0maXWfBzMysXv1dBJ6W//8gsB2whDS8wxvzNDMzG6X66wLaAbgO2LuHed3ANwe9RGZmNiT6\nDABJp+b/ZzSmRcQGwD9L8tANZmajWLs3gh0N7AacBPwGWBIRP5B0Sp2FMzOz+rQ7GNzxwCeAQ4Ef\nAlsDb62rUGZmVr+2fxFM0lOk0T2vz8M6r1NbqczMrHbtBsBvI+I6YBPgxxHxfeDe+oplZmZ1azcA\njgK+COws6XngsjzNzMxGqT4vAkfEsZJmASfnSW+q/B7AG4HP1Vg2MzOrUX/fAupo+d/MzNYQ/Q0G\nd2H+83TgN5JOIw0N/Rd89m9mNqq1ew1gFvDuyuO9ga8PfnHMzGyotPubwDtI2hpA0pPAByLigfqK\nZWZmdWu3BdAZEa9uPIiIVwIr6ymSmZkNhXZbAKcDv4mIO0gXhHcEPlJbqczMrHbt/h7Ad0jDQV8O\nXArsKOmqOgtmZmb1aisAImJt4EjgIOBnwIfyNDMzG6XavQbwNWAcqRXwArApcFFdhTIzs/q1GwDb\nSzoZeEHSUuAI0p3AZmY2SrUbAN25y6c7P96w8reZmY1C7QbAOcCPgVdFxDmkkUC/XFupzMysdu1+\nDfRG4FekO4DHAAdK8o1gZmajWLsBcLukLYC5dRbGzMyGTrsBcH9EfBC4G1jWmCjpv2splZmZ1a7d\nANiJdPdvdVjobtIvhJmZ2SjU3w/CTAbOA54B7gBmSnp6KApmZmb16u9bQBcD84BPAC8Dzq69RGZm\nNiT66wLaSNL+ABFxK3Bf/UUyM7Oh0F8L4PnGH5JeqD42M7PRrd2LwA1t3/0bEZ3A+cAU4DngGEnz\ne3jeLOApSTNXsyxmZjYA/QXAlhHxx8rjjfLjDqBbUl/fApoOjJW0S0TsDJxFGk30HyLiw8DWpBFG\nzcxsCPUXAJsNYN27AzcBSJoTEVOrMyNiV9LXSy8ENu9vZRMmrEtX15gBFGdkmDRp/HAXYcRwXTS5\nLppcF01110WfASDpzwNY9/rAosrjFRHRJWl5/nnJU4F3Aoe0s7KFC5cOoCgjx4IFS4a7CCOG66LJ\nddHkumgajLroK0RW9xrA6lgMVLfcKWl5/vtg0oiiNwCvAtaNiHmSLqmxPGZmVlFnANwJHAh8P18D\neLAxQ9JXgK8ARMSRwOY++JuZDa06A+BqYL+IuIt00XhGRBwGjJM0q8btmplZG2oLAEkrgeNaJs/r\n4XmX1FUGMzPrXbs/CGNmZmsYB4CZWaEcAGZmhXIAmJkVygFgZlYoB4CZWaEcAGZmhXIAmJkVygFg\nZlYoB4CZWaEcAGZmhXIAmJkVygFgZlYoB4CZWaEcAGZmhXIAmJkVygFgZlYoB4CZWaEcAGZmhXIA\nmJkVygFgZlYoB4CZWaEcAGZmhXIAmJkVygFgZlYoB4CZWaEcAGZmhXIAmJkVygFgZlYoB4CZWaEc\nAGZmhXIAmJkVygFgZlYoB4CZWaG66lpxRHQC5wNTgOeAYyTNr8w/FPgosBx4EDhe0sq6ymNmZquq\nswUwHRgraRdgJnBWY0ZErAN8Adhb0m7ABsC0GstiZmYt6gyA3YGbACTNAaZW5j0H7CppaX7cBTxb\nY1nMzKxFbV1AwPrAosrjFRHRJWl57up5HCAi/g0YB9zS18omTFiXrq4xtRV2qEyaNH64izBiuC6a\nXBdNroumuuuizgBYDFRL3ylpeeNBvkbwRWAz4N2Suvta2cKFS/uaPWosWLBkuIswYrgumlwXTa6L\npsGoi75CpM4uoDuBAwAiYmfShd6qC4GxwPRKV5CZmQ2ROlsAVwP7RcRdQAcwIyIOI3X33AscDdwO\n3BYRAOdKurrG8piZWUVtAZD7+Y9rmTyv8rfvQTAzG0Y+CJuZFcoBYGZWKAeAmVmhHABmZoVyAJiZ\nFcoBYGZWKAeAmVmhHABmZoVyAJiZFcoBYGZWKAeAmVmhHABmZoVyAJiZFcoBYGZWKAeAmVmhHABm\nZoVyAJiZFcoBYGZWKAeAmVmhHABmZoVyAJiZFcoBYGZWKAeAmVmhHABmZoVyAJiZFcoBYGZWKAeA\nmVmhHABmZoVyAJiZFcoBYGZWKAeAmVmhHABmZoVyAJiZFcoBYGZWqK66VhwRncD5wBTgOeAYSfMr\n8w8EPgMsB2ZL+kZdZTEzsxerswUwHRgraRdgJnBWY0ZErAV8GXgLsBdwbET8U41lMTOzFnUGwO7A\nTQCS5gBTK/O2AOZLWijpeeAOYM8ay2JmZi1q6wIC1gcWVR6viIguSct7mLcE2KCvlU2aNL5joAW6\n9qyDBrqKNYbrosl10eS6aCqhLupsASwGxle3lQ/+Pc0bDzxdY1nMzKxFnQFwJ3AAQETsDDxYmfcw\n8IaImBgRa5O6f35RY1nMzKxFR3d3dy0rrnwLaBugA5gBbAeMkzSr8i2gTtK3gL5WS0HMzKxHtQWA\nmZmNbL4RzMysUA4AM7NCOQDMzArlAGhTRByb72Bu9/kn1Fme4RARYyPiT73Me1VEnD+0JRo8EdEV\nET+JiLsiYkKby+wZEdvUXbbRLCLOiYjXDHc5Blv+LBzTx/w+3xsRcWREnFFP6drnAGjfycCY1Xj+\nKXUVZCSS9Jik44e7HAMwGVhf0q6SFra5zFF5OeuFpI9K+u/hLkcNXgX0GgCMkvdGMd8Cioh1gIuB\njYG1gY8CHwY2IR3Yz5b0vYj4KXAfsBXpjuWDgX2Br5GGtjgH+A/geWAWsAz4V2AtoBt4Z17vqcB/\nAh/J211lO7W/4EESEeOAbwMTgPnAPsCfeHEddQDflbTz8JR0YCLiBtLwJVcArwTGAq8GTpF0TURM\nI+3TDuDXwIXA9cATwDTgHkmvyuv6LnAB8FrSgaAzL7sF8C5gPeBJ4J15KJQRJSKOJN3Dsy7wetL7\n/X7gq8AK4FngQ6TX9T3gL6TX+l3Se+KNwPWSTs6fp+OA9wGvI9XtxsDHJN0cEe+h5fMj6cmheJ0D\nERHfAN4LnAnsSPocdJFO/Bax6nvjHbTsd+AwYHNJM4e88BUltQCOA/6UB6d7H2kQugWSdiUd4L8Q\nERvm594jaV/gFuBQSRcBj+XlIA1yt4eky4DNgLdL2h2YC+wv6XTgqXxG/OE+tjMaHAc8JGlP0kGv\nYZU6GpaSDa7jSfvvcuAsSfsBxwL/GhFdwHmk/TyVFIQLSCcEn+znDHdhfm/8BHgFsK+knUgHix1q\nezUDt4GkxsFrJvAN4ARJe5Hu7zk7P28T4GjSge7zwInATnlaq+ckvY10UvSxPO1Fn596Xs6gO51U\n3vWBW/Ln42DgItIJwk3AJ4H/xwje7yUFQJDvNpb0e9LZ3c/z4yWknfn6/Nzf5P//QjoTbKXK308A\nl0bExaSb3lqvE2zRx3ZGg82AewAk3Q28kKf3V0ej1aPAhyPiMlL4rQVsSDqQPwEg6Yv9HPSr41Yp\nL7OS1Gq8PCIuAv6ZF79XRpL78v+N/TtZUmPaz4Et899/lLSINJTL45KekvQs6Wy+VU/vmf4+PyNd\n9fP9V9IwN69szBzp+72kAHiYnLwRsQnprHWP/Hg8sDXwX/m5Pb15V9Ksr5V5uQ2A00gtg2NI3UGN\nD3/j/4f72M5oMBfYBSAi3kjzzbum9h1+HvimpA+Qzto7SAepl0fERICI+EpE7Miq74m1ImJcHtpk\ny8r6Gu+VbYDpkt4L/FtebsADHNaodf8+UrmouRfwu16e1/Y6+/n8jHSNfV/9fG9E6ir9W2P+SN/v\nJQXAhcAmEfEz4JvAW4FXRMQdwE+B0xpneL24HbiBVXfeYtKYR7/I85fRvPAzNyK+RbpOsDrbGWku\nINXbHaS+2ueGuTx1uwI4MyJ+DuwHbJjP4o4Hrs/10AH8ErgbOCMitiBdG5oDXAn8uYf1zgeeiYg7\nSd1mjzIKLhJWfAg4LyJuZ9UunIHo6/Mz0j1Bupa4AbBPfr9cAxybB728GziDdM1kxO73Yi4Cm5nZ\nqkpqAZiZWYUDwMysUA4AM7NCOQDMzArlADAzK1SdPwpvNmwi4rWk76rPzZPWAR4g3c36+HCVqx35\npqjPSurp66Rmg8YtAFuTPSJpW0nbApuTvot/5TCXqR17M4JuFrI1l+8DsDVSbgH8VNJrK9PWBh4n\n3ck6DXg/6UadH5HG9FkRER8jDQGxArhW0kkRcUle1yV5Pd2SOiLis8BrgCmk2/9PIQ2WtxNp8LT3\nSeqOiJnAIaTBAG8GTiINiHY18BBp8LTHSWPJHAt8jhRWewBvAM4lDZ3wJPBhSfMHt7asVG4BWDHy\nyJu/B7YlDXK2PenguylwXB7e4XjS6I7bANtHxPb9rHZr0gH//cBs0siZWwHbAdtExFvzdnbI29oI\nODwvO4U0OuxWpLF0Dpd0BvAIaTTOJaQRNk+QNIV0V/blA6wGs39wAFhpuklDGVwuaVm+bX828GZg\nT9JZ/yJJyyXtK+lX/azvlryOPwOPSpqbH/+VNC7MvqSA+BVplMipNMcKekJSY4C0h4CJLevejDQI\n3S8BJF0BbJrH0DEbMF8EtmLkLqAgDfJW1UH6LLzQ8vzJwFJSaHTkaa0jOVbH81/ew2bHAOdIOjsv\n//L8vA1J4+o3/GMbFT2doHWwej9MZNYrtwCsCBHRSRp5cg5pzPZDI2KdPNb/DFIo3A68LY/q2UXq\nbplK6ntvnLVPX81N3wZ8oLLOa4D39LPMclIgiTSQYGMU20OAP0t6ajXLYNYjtwBsTTY5Ihpj2I8h\njUd/mKSnImJb4F7SZ+Bm4KuSlkfEeaTRKTuBqyT9OCL+CHwvIh4gHdAfbbcAkq6NiCmk0SHHkH4o\n5FLSReDeXEcaeXZ/0q9OnRcR6wFP5cdmg8LfAjIzK5S7gMzMCuUAMDMrlAPAzKxQDgAzs0I5AMzM\nCuUAMDMrlAPAzKxQ/x/SQskbVtNsSgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f39f77dcf98>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cnn_results = accu_df_cnn.plot(kind=\"bar\", rot=0, legend=False)\n",
    "cnn_results.set_xlabel(\"Documento\")\n",
    "cnn_results.set_ylabel(\"Precisión\")\n",
    "cnn_results.set_title(\"Precisión por cada Documento: CNN\")\n",
    "plt.savefig(images_path+'analysis_cnn.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "As you can see, the global accuracy is close to ~0.8. While the accuracy for the DNI is close to 1, the accuracy for the rest of the documents range between 0.6 and 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
